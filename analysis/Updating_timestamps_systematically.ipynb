{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T12:59:15.291926Z",
     "start_time": "2025-12-16T12:59:15.234066Z"
    }
   },
   "source": [
    "## ðŸš€ Setup and Helper Functions\n",
    "\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Helper function for timestamp manipulation ---\n",
    "\n",
    "def get_new_timestamps(timestamps):\n",
    "    \"\"\"\n",
    "    Rounds a list of timestamps to the nearest 500 milliseconds (0, 500)\n",
    "    and ensures the resulting list is strictly increasing, using a minimum\n",
    "    100ms step to resolve collisions.\n",
    "\n",
    "    Args:\n",
    "        timestamps (list): A list of original timestamp strings.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of new, unique, rounded timestamp strings,\n",
    "              in the same chronological order as the input.\n",
    "    \"\"\"\n",
    "    if not timestamps:\n",
    "        return []\n",
    "\n",
    "    # Convert original timestamps to datetime objects for sorting and manipulation\n",
    "    datetime_objects = sorted([\n",
    "        datetime.fromisoformat(ts.replace('Z', '+00:00')) for ts in timestamps\n",
    "    ])\n",
    "\n",
    "    new_datetime_objects = []\n",
    "    previous_timestamp = None\n",
    "\n",
    "    for timestamp in datetime_objects:\n",
    "\n",
    "        # 1. Calculate the closest half-second mark (Target Time)\n",
    "        milliseconds = timestamp.microsecond // 1000\n",
    "        remainder = milliseconds % 500\n",
    "\n",
    "        if remainder < 250:\n",
    "            milliseconds -= remainder\n",
    "        else:\n",
    "            milliseconds += (500 - remainder)\n",
    "\n",
    "        # Handle overflow: e.g., 999ms rounds up to 1000ms (which is 1 second)\n",
    "        if milliseconds == 1000:\n",
    "            rounded_timestamp = timestamp + timedelta(seconds=1)\n",
    "            rounded_timestamp = rounded_timestamp.replace(microsecond=0)\n",
    "        else:\n",
    "            rounded_timestamp = timestamp.replace(microsecond=milliseconds * 1000)\n",
    "\n",
    "        # 2. Ensure strictly increasing uniqueness with 100ms increment\n",
    "        # If the target rounded time is less than or equal to the previous,\n",
    "        # shift it forward by 100ms from the previously assigned time.\n",
    "        if previous_timestamp and rounded_timestamp <= previous_timestamp:\n",
    "            # Collision detected. Shift forward by 100ms.\n",
    "            rounded_timestamp = previous_timestamp + timedelta(milliseconds=100)\n",
    "\n",
    "        previous_timestamp = rounded_timestamp\n",
    "        new_datetime_objects.append(rounded_timestamp)\n",
    "\n",
    "    # 3. Convert back to the required string format\n",
    "    new_timestamps_str = [\n",
    "        ts.isoformat().replace('+00:00', 'Z') for ts in new_datetime_objects\n",
    "    ]\n",
    "\n",
    "    return new_timestamps_str\n",
    "\n",
    "def update_timestamps(data):\n",
    "    \"\"\"\n",
    "    Updates timestamps in 'gameMoves' and 'doSomethingTimestamps' ensuring\n",
    "    no two final timestamps are the same across the entire file.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The loaded JSON data from a game file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The data dictionary with updated timestamps.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Collect all timestamps and corresponding values\n",
    "    original_game_moves = data['gameMoves']\n",
    "    original_do_something_timestamps = data['doSomethingTimestamps']\n",
    "\n",
    "    # Combine all original timestamps for global chronological processing\n",
    "    all_original_timestamps = sorted(\n",
    "        list(original_game_moves.keys()) + list(original_do_something_timestamps.keys())\n",
    "    )\n",
    "\n",
    "    # 2. Generate the globally unique and sorted new timestamps\n",
    "    all_new_timestamps = get_new_timestamps(all_original_timestamps)\n",
    "\n",
    "    # Create an ordered mapping: Original TS -> New TS\n",
    "    ts_mapping = dict(zip(all_original_timestamps, all_new_timestamps))\n",
    "\n",
    "    # 3. Rebuild the two dictionaries using the mapping, guaranteeing no loss\n",
    "    new_game_moves = {}\n",
    "    for original_ts, move_value in original_game_moves.items():\n",
    "        new_ts = ts_mapping[original_ts]\n",
    "        new_game_moves[new_ts] = move_value\n",
    "\n",
    "    new_do_something_timestamps = {}\n",
    "    for original_ts, action_value in original_do_something_timestamps.items():\n",
    "        new_ts = ts_mapping[original_ts]\n",
    "        new_do_something_timestamps[new_ts] = action_value\n",
    "\n",
    "    # 4. Update the data dictionary\n",
    "    data['gameMoves'] = new_game_moves\n",
    "    data['doSomethingTimestamps'] = new_do_something_timestamps\n",
    "\n",
    "    return data\n",
    "\n",
    "# --- Main processing function ---\n",
    "\n",
    "def process_files(file_list, output_prefix='_updated'):\n",
    "    \"\"\"\n",
    "    Processes a list of JSON files to update timestamps and saves the\n",
    "    result to a new file with the specified prefix.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting file processing for {len(file_list)} files ---\")\n",
    "\n",
    "    for input_filepath in file_list:\n",
    "        try:\n",
    "            # 1. Determine the output filename\n",
    "            directory = os.path.dirname(input_filepath)\n",
    "            filename_with_ext = os.path.basename(input_filepath)\n",
    "            name, ext = os.path.splitext(filename_with_ext)\n",
    "\n",
    "            # Construct the new filename: insert '_updated' before the final number\n",
    "            last_underscore_index = name.rfind('_')\n",
    "            if last_underscore_index != -1 and name[last_underscore_index+1:].isdigit():\n",
    "                base_name = name[:last_underscore_index]\n",
    "                suffix = name[last_underscore_index:]\n",
    "                new_name = f\"{base_name}{output_prefix}{suffix}\"\n",
    "            else:\n",
    "                new_name = f\"{name}{output_prefix}\"\n",
    "\n",
    "            output_filepath = os.path.join(directory, f\"{new_name}{ext}\")\n",
    "\n",
    "            print(f\"\\nProcessing: {input_filepath}\")\n",
    "\n",
    "            # 2. Load the data\n",
    "            with open(input_filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Check original lengths before update\n",
    "            original_gm_len = len(data['gameMoves'])\n",
    "            original_dst_len = len(data['doSomethingTimestamps'])\n",
    "            total_original = original_gm_len + original_dst_len\n",
    "\n",
    "            # 3. Update the timestamps\n",
    "            updated_data = update_timestamps(data)\n",
    "\n",
    "            # Check final lengths after update\n",
    "            final_gm_len = len(updated_data['gameMoves'])\n",
    "            final_dst_len = len(updated_data['doSomethingTimestamps'])\n",
    "            total_final = final_gm_len + final_dst_len\n",
    "\n",
    "            if total_original != total_final:\n",
    "                raise ValueError(\n",
    "                    f\"DATA MISMATCH: Original total count ({total_original}) \"\n",
    "                    f\"does not match final total count ({total_final}).\"\n",
    "                )\n",
    "\n",
    "            # 4. Save the new data\n",
    "            with open(output_filepath, 'w') as f:\n",
    "                json.dump(updated_data, f, indent=4)\n",
    "\n",
    "            print(f\"Output to: {output_filepath}\")\n",
    "            print(f\"Successfully updated and saved. Total moves maintained: {total_final}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"!!! FATAL ERROR processing {input_filepath}: {e}\")\n",
    "\n",
    "# --- Execution Cell ---\n",
    "\n",
    "# Define the pattern to find all relevant JSON files.\n",
    "# ADJUST THIS PATH if your files are in a different location.\n",
    "file_pattern = '../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)/*.json'\n",
    "\n",
    "# Get the list of all files to process\n",
    "all_files_to_process = glob.glob(file_pattern)\n",
    "\n",
    "# Execute the main function\n",
    "process_files(all_files_to_process)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting file processing for 11 files ---\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_1.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_1.json\n",
      "Successfully updated and saved. Total moves maintained: 472\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_10.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_10.json\n",
      "Successfully updated and saved. Total moves maintained: 640\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_2.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_2.json\n",
      "Successfully updated and saved. Total moves maintained: 964\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_3.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_3.json\n",
      "Successfully updated and saved. Total moves maintained: 557\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_4.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_4.json\n",
      "Successfully updated and saved. Total moves maintained: 444\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_5.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_5.json\n",
      "Successfully updated and saved. Total moves maintained: 520\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_6.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_6.json\n",
      "Successfully updated and saved. Total moves maintained: 185\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_7.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_7.json\n",
      "Successfully updated and saved. Total moves maintained: 591\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_8.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_8.json\n",
      "Successfully updated and saved. Total moves maintained: 517\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_9.json\n",
      "Output to: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_updated_9.json\n",
      "Successfully updated and saved. Total moves maintained: 511\n",
      "\n",
      "Processing: ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_overview.json\n",
      "!!! FATAL ERROR processing ../output/all/Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)\\Two, one and one (2 SHORT_FUSE, 1 BASIC, 1 REACTIVE)_overview.json: 'gameMoves'\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
